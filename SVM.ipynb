{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification**\n",
    "\n",
    "Prerequisite：Linearly separable\n",
    "\n",
    "Basic idea is Max Margin Classifier, we have to find the widest road between class1 and class2.\n",
    "\n",
    "\\begin{align}\n",
    "max:margin(w,b)\n",
    "\\\\st.\n",
    "\\left\\{\\begin{matrix}\n",
    "w^Tx_i +b>0,y_i=+1\\\\ \n",
    "w^Tx_i +b<0,y_i=-1\n",
    "\\end{matrix}\\right.\n",
    "\\\\\n",
    " \\Rightarrow y_i(w^{T}x_{i}+b) > 0\\\\\n",
    " \\forall i=1,2,...,N\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For the hard margin:\n",
    "\n",
    "   * We set margin equals 1, and $y_i(w^Tx_i+b)\\geqslant1$;\n",
    "    \n",
    "2. For the soft margin:\n",
    "\n",
    "   * We allow some noise, so that we can increase the robustness of our system. \n",
    "   \n",
    "   * We introduced slckness variable $\\xi$, which represent **loss**. \n",
    "   \n",
    "   * And now the margin function changes to $y_i(w^Tx_i+b)\\geqslant1-\\xi_i,s.t.xi\\geqslant0$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have two classes X and O, for class X:\n",
    "\n",
    "   1. When X is correctly classified, means X locates outside the margin, then $\\xi=0$\n",
    "   2. WHen X is incorrecly classified and locates on the right side of $y_i(w^Tx_i+b)\\geqslant0$,then $0<\\xi\\leqslant0$ \n",
    "   3. When X is on the other side of margin, which means $y_i(w^Tx_i+b)\\leqslant0$, then $\\xi>1$\n",
    "   \n",
    "Based on these 3 conditions, we get the new target funtion:\n",
    "\n",
    "\\begin{align}\n",
    "min_{w,b,\\xi }:\\frac{1}{2}\\left \\| w \\right \\|^{2}+C\\sum_{i=1}^{N}\\xi_i\\\\\n",
    "s.t. \\left\\{\\begin{matrix}y_i(w^Tx_i + b)\\geqslant 1-\\xi_i\n",
    "\\\\ \\xi_i\\geqslant0\\\\\n",
    "\\end{matrix}\\right.\n",
    "\\\\\n",
    "\\end{align}\n",
    "\n",
    "The loss function here called **Hinge Loss**, basically it uses distance to measure **loss**: $\\xi$ represents the distance from a point to its corresponding margin $w^Tx+b=1$ when it is miss-classified.\n",
    "\n",
    "   1. If $w^Tx+b\\geqslant1$, $\\xi_i=0$, No loss, correct.\n",
    "   2. If $w^Tx+b<1$, $\\xi_i=1-y_i(w^Tx+b)$\n",
    "   \n",
    "So now we have:\n",
    "   \\begin{align}\n",
    "\\xi_i =max\\left \\{ 0,1-y_i(w^Tx_i + b) \\right \\}\n",
    "\\end{align}\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base on lagrange duality and KKT conditions, now we get the new target:\n",
    "\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "min: \\sum_{i=1}^{N}\\alpha_i - \\frac{1}{2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_i\\alpha_jy_iy_jX_i^TX_j\\\\\n",
    "s.t.  \\left\\{\\begin{matrix}\n",
    "0< \\alpha_i<C\\\\\n",
    "\\sum_{i=1}^{N}\\alpha_iy_i=0\n",
    "\\end{matrix}\\right.\n",
    "\\\\\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal Solutions:\n",
    "\n",
    "$W^* = \\sum_{i=1}^{N}x_iy_i\\alpha_i$\n",
    "\n",
    "$b^* = y_i-w^Tx_i$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMO: Sequential Minimal Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic idea: SGD and paired $\\alpha$\n",
    "\n",
    "Each time, we only update tow $\\alpha$s, the rest of them were treated as constant **Const**.\n",
    "\n",
    "Now set:\n",
    "\n",
    "1. $K_{ij} = X_i^TX_j$\n",
    "2. $f(x_k)=\\sum_{i=1}^{N}\\alpha_iy_iX_i^Tx_k+b$\n",
    "3. Error: $E_i = f(x_i)-y_i$\n",
    "4. $\\xi=K_{mm}+K_{nn}-2K_{mn}$\n",
    "\n",
    "Then we get:\n",
    "\n",
    "1. $\\alpha_2^{new} = \\alpha_2^{old} + y_2\\frac{(E_1-E_2)}{\\xi}$\n",
    "2. $\\alpha_1^{new}=\\alpha_1^{old}+y_1y_2(\\alpha_2^{old}-\\alpha_2^{new})$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data: feature and target should be in matrix form\n",
    "# data_mat, label_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to randomly choose a paired alpha j\n",
    "def select_rand_j(i,maximun_number):\n",
    "    # i is the input index of alpha, and we need to find a j that is different from i\n",
    "    # maximun_number is the maximun # of samples or rows\n",
    "    j = i\n",
    "    while j==i:\n",
    "        j = int(random.uniform(0,maximun_number))\n",
    "    return j\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on KKT condition, $\\sum_{i=1}^{N}\\alpha_iy_i=0$, and each time we only update two $\\alpha$\n",
    "\n",
    "we have $\\alpha_1y_1 + \\alpha_2y_2 + \\sum_{i=3}^{N}\\alpha_iy_i = 0$\n",
    "\n",
    "and $\\alpha_1^{new}y_1 + \\alpha_2^{new}y_2 = \\alpha_1^{old}y_1 + \\alpha_2^{old}y_2 = Constant K$\n",
    "\n",
    "So, for each pair of $\\alpha$, there are upper and lower limits for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_alpha(alpha, H, L):\n",
    "    if alpha > H:\n",
    "        alpha = H\n",
    "    elif alpha < L:\n",
    "        alpha = L\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "class svc():\n",
    "    def __init__(self,data_mat,label_mat,C,tolerance,iteration,kernel):\n",
    "        self.C = 0.6\n",
    "        self.data_mat = data_mat\n",
    "        self.label_mat = label_mat\n",
    "        self.tolerance = 0.001\n",
    "        self.iteration = 10\n",
    "        self.kernel = kernel\n",
    "    \n",
    "    # feature scaling\n",
    "    def feature_scale(self):\n",
    "        # Normalization\n",
    "        m,n = np.shape(self.data_mat)\n",
    "        for i in range(n):\n",
    "            X_min = np.min(self.data_mat[:,i])\n",
    "            X_max = np.max(self.data_mat[:,i])\n",
    "            if X_max-X_min == 0:\n",
    "                self.data_mat[:,i] = self.data_mat[:,i]\n",
    "            else:\n",
    "                self.data_mat[:,i] = (self.data_mat[:,i] - X_min)/(X_max-X_min)\n",
    "        \n",
    "    # now define smo function\n",
    "    def smo_simple(self):\n",
    "        # data_mat: feature matrix m*n\n",
    "        # label_mat: label matrix m*1\n",
    "        # C: hyperparameter\n",
    "        b = 0\n",
    "        m, n = np.shape(self.data_mat)\n",
    "        alpha = np.zeros((m,1))\n",
    "        iter = 0\n",
    "        while iter < self.iteration:\n",
    "            # randomly choose an alpha i\n",
    "            # i = rand,uniform(0,m)\n",
    "            alpha_pairs_changed = 0\n",
    "            for i in range(m):\n",
    "                wT = np.dot(np.multiply(alpha,self.label_mat).T,self.data_mat)\n",
    "                f_xi = np.dot(wT,self.data_mat[i,:].T) + b\n",
    "                E_i = f_xi - float(self.label_mat[i])\n",
    "                # if the error is less than tolerance, we stop.\n",
    "                # if E_i * y_i > tolerance, this point locates on the right side\n",
    "                # if E_i * y_i < tolerance, this point locates on the wrong side, and alpha needs to be updated\n",
    "                if ((E_i * self.label_mat[i,:] < -self.tolerance) and (alpha[i]<self.C)) or \\\n",
    "                (( E_i * self.label_mat[i,:] > self.tolerance) and (alpha[i] > 0)): \n",
    "                    ####?????????????????????????????????\n",
    "                    # Now we need find its paired alpha j\n",
    "                    j = select_rand_j(i,m)\n",
    "                    f_xj = float(np.dot(wT,self.data_mat[j,:].T)) + b\n",
    "                    E_j = f_xj - float(self.label_mat[j])\n",
    "\n",
    "                    # \n",
    "                    if (self.label_mat[i] != self.label_mat[j]):\n",
    "                        # alpha1 - alpha2 = Constant\n",
    "                        # alpha1 = C - alpha2\n",
    "                        # 0 < alpha < C\n",
    "                        L = max(0,alpha[j] - alpha[i])\n",
    "                        H = min(self.C ,self.C + alpha[j] - alpha[i])\n",
    "                    else:\n",
    "                        # alpha1+alpha2 = constant\n",
    "                        L = max(0,alpha[j] + alpha[i] - self.C) #??????????????????????\n",
    "                        H = min(self.C, alpha[j] + alpha[i])\n",
    "                    if L==H:\n",
    "                        continue\n",
    "                    alpha_j_old = alpha[j].copy()\n",
    "                    alpha_i_old = alpha[i].copy()\n",
    "                    \n",
    "                    # 𝜉=𝐾𝑚𝑚+𝐾𝑛𝑛−2𝐾𝑚𝑛\n",
    "#                     eta = np.dot(self.data_mat[i,:],self.data_mat[i,:].T) + np.dot(self.data_mat[j,:],self.data_mat[j,:].T) -\\\n",
    "#                     2.0 * np.dot(self.data_mat[i,:],self.data_mat[j,:].T)\n",
    "                    eta = -np.dot(self.data_mat[i,:],self.data_mat[i,:].T) - np.dot(self.data_mat[j,:],self.data_mat[j,:].T) +\\\n",
    "                    2.0 * np.dot(self.data_mat[i,:],self.data_mat[j,:].T)\n",
    "                    if eta >= 0:\n",
    "                        #print('eta')\n",
    "                        continue\n",
    "                    \n",
    "                    alpha[j] = alpha[j] - self.label_mat[j]*(E_i-E_j)/eta\n",
    "                    alpha[j] = clip_alpha(alpha[j],H,L)\n",
    "                    if (abs(alpha[j] - alpha_j_old) < 0.00001): #self.tolerance\n",
    "                        #print('tolerance')\n",
    "                        continue\n",
    "\n",
    "                    #𝛼𝑛𝑒𝑤1=𝛼𝑜𝑙𝑑1+𝑦1𝑦2(𝛼𝑜𝑙𝑑2−𝛼𝑛𝑒𝑤2)\n",
    "                    alpha[i] = alpha[i] + self.label_mat[i]*self.label_mat[j]*(alpha_j_old-alpha[j])\n",
    "\n",
    "\n",
    "                    # calculate b\n",
    "\n",
    "                    b1_new = b - E_i - self.label_mat[i]*(alpha[i] - alpha_i_old)*np.dot(self.data_mat[i,:],self.data_mat[i,:].T)\\\n",
    "                                - self.label_mat[j]*(alpha[j]-alpha_j_old)*np.dot(self.data_mat[i,:],self.data_mat[j,:].T)\n",
    "                    b2_new = b - E_j - self.label_mat[i]*(alpha[i] - alpha_i_old)*np.dot(self.data_mat[i,:],self.data_mat[j,:].T)\\\n",
    "                                - self.label_mat[j]*(alpha[j]-alpha_j_old)*np.dot(self.data_mat[j,:],self.data_mat[j,:].T)\n",
    "                    if (0 < alpha[i]< self.C):\n",
    "                        b = b1_new\n",
    "                    elif (0 < alpha[j]< self.C):\n",
    "                        b = b2_new\n",
    "                    else:\n",
    "                        b = (b1_new + b2_new)/2.0\n",
    "                    alpha_pairs_changed += 1\n",
    "            if (alpha_pairs_changed == 0): iter += 1\n",
    "            else: iter = 0\n",
    "        return b, alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "feature = pd.DataFrame(cancer.data,columns=cancer.feature_names)\n",
    "target = pd.DataFrame(cancer.target,columns=['target'])\n",
    "df = pd.concat([feature,target],axis=1)\n",
    "type(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = feature.to_numpy()\n",
    "data_mat = np.asmatrix(feature)\n",
    "target = target.to_numpy()\n",
    "label_mat = np.asmatrix(target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "feature = pd.DataFrame(iris.data,columns=iris.feature_names)\n",
    "target = pd.DataFrame(iris.target,columns=['target'])\n",
    "df = pd.concat([feature,target],axis=1)\n",
    "df = df[df['target']!=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1c53e2d0>"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =df.reset_index()\n",
    "target = df['target'].to_frame()\n",
    "feature = df.drop('target',axis=1)\n",
    "type(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = feature.to_numpy()\n",
    "data_mat = np.asmatrix(feature)\n",
    "target = target.to_numpy()\n",
    "label_mat = np.asmatrix(target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = svc(data_mat = data_mat,label_mat = label_mat, C = 0.6, tolerance = 0.001,iteration = 10,kernel= 'RBF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.feature_scale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b,alpha = svm.smo_simple()\n",
    "alpha[alpha>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
